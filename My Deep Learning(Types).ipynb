{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from numpy import where\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "import os\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "\n",
    "\n",
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import categorical_crossentropy\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "\n",
    "import shutil\n",
    "import random\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "keras = tf.compat.v2.keras\n",
    "Sequence = keras.utils.Sequence\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Year - Fiscal</th>\n",
       "      <th>Tobin's Q</th>\n",
       "      <th>EPS</th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Productivity</th>\n",
       "      <th>Leverage Ratio</th>\n",
       "      <th>Asset Turnover</th>\n",
       "      <th>Operational Margin</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Market Book Ratio</th>\n",
       "      <th>Assets Growth</th>\n",
       "      <th>Sales Growth</th>\n",
       "      <th>Employee Growth</th>\n",
       "      <th>BK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1979</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.58</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.77</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.15</td>\n",
       "      <td>2.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1980</td>\n",
       "      <td>0.98</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>1.31</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.41</td>\n",
       "      <td>0.126</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.040</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1981</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.56</td>\n",
       "      <td>0.368</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1982</td>\n",
       "      <td>1.13</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.80</td>\n",
       "      <td>1.39</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>5.28</td>\n",
       "      <td>-0.021</td>\n",
       "      <td>-0.119</td>\n",
       "      <td>-0.096</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1983</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.04</td>\n",
       "      <td>8.68</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.147</td>\n",
       "      <td>0.053</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Year - Fiscal  Tobin's Q   EPS  Liquidity  Profitability  \\\n",
       "0                1979       0.98  1.58       0.36           0.18   \n",
       "1                1980       0.98  1.41       0.36           0.19   \n",
       "2                1981       0.87  0.31       0.32           0.13   \n",
       "3                1982       1.13  0.71       0.28           0.14   \n",
       "4                1983       1.26  0.75       0.41           0.13   \n",
       "\n",
       "   Productivity  Leverage Ratio  Asset Turnover  Operational Margin  \\\n",
       "0          0.13            1.33            1.77                0.07   \n",
       "1          0.12            1.31            1.59                0.07   \n",
       "2          0.08            1.03            1.55                0.05   \n",
       "3          0.08            0.80            1.39                0.06   \n",
       "4          0.08            0.20            1.30                0.06   \n",
       "\n",
       "   Return on Equity  Market Book Ratio  Assets Growth  Sales Growth  \\\n",
       "0              0.15               2.22            NaN           NaN   \n",
       "1              0.13               2.41          0.126         0.014   \n",
       "2              0.04               2.56          0.368         0.328   \n",
       "3              0.05               5.28         -0.021        -0.119   \n",
       "4              0.04               8.68          0.233         0.147   \n",
       "\n",
       "   Employee Growth  BK  \n",
       "0              NaN   0  \n",
       "1            0.040   0  \n",
       "2            0.567   0  \n",
       "3           -0.096   0  \n",
       "4            0.053   0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"bankruptcy_data.csv\",sep=\",\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 92872 entries, 0 to 92871\n",
      "Data columns (total 15 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Data Year - Fiscal  92872 non-null  int64  \n",
      " 1   Tobin's Q           92620 non-null  float64\n",
      " 2   EPS                 92867 non-null  float64\n",
      " 3   Liquidity           92625 non-null  float64\n",
      " 4   Profitability       92625 non-null  float64\n",
      " 5   Productivity        92625 non-null  float64\n",
      " 6   Leverage Ratio      92846 non-null  float64\n",
      " 7   Asset Turnover      92625 non-null  float64\n",
      " 8   Operational Margin  87315 non-null  float64\n",
      " 9   Return on Equity    92864 non-null  float64\n",
      " 10  Market Book Ratio   92815 non-null  float64\n",
      " 11  Assets Growth       86171 non-null  float64\n",
      " 12  Sales Growth        86171 non-null  float64\n",
      " 13  Employee Growth     85862 non-null  float64\n",
      " 14  BK                  92872 non-null  int64  \n",
      "dtypes: float64(13), int64(2)\n",
      "memory usage: 10.6 MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.979e+03,  9.800e-01,  1.580e+00, ...,  0.000e+00,  0.000e+00,\n",
       "         0.000e+00],\n",
       "       [ 1.980e+03,  9.800e-01,  1.410e+00, ...,  1.400e-02,  4.000e-02,\n",
       "         0.000e+00],\n",
       "       [ 1.981e+03,  8.700e-01,  3.100e-01, ...,  3.280e-01,  5.670e-01,\n",
       "         0.000e+00],\n",
       "       ...,\n",
       "       [ 2.011e+03,  9.240e-01, -1.600e-02, ..., -2.000e-02, -1.050e-01,\n",
       "         0.000e+00],\n",
       "       [ 2.012e+03,  7.880e-01, -1.330e-01, ..., -1.710e-01, -5.900e-02,\n",
       "         0.000e+00],\n",
       "       [ 2.013e+03,  8.850e-01, -6.480e-01, ...,  6.500e-02,  6.300e-02,\n",
       "         1.000e+00]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.nan_to_num(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Data Year - Fiscal</th>\n",
       "      <th>Tobin's Q</th>\n",
       "      <th>EPS</th>\n",
       "      <th>Liquidity</th>\n",
       "      <th>Profitability</th>\n",
       "      <th>Productivity</th>\n",
       "      <th>Leverage Ratio</th>\n",
       "      <th>Asset Turnover</th>\n",
       "      <th>Operational Margin</th>\n",
       "      <th>Return on Equity</th>\n",
       "      <th>Market Book Ratio</th>\n",
       "      <th>Assets Growth</th>\n",
       "      <th>Sales Growth</th>\n",
       "      <th>Employee Growth</th>\n",
       "      <th>BK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Data Year - Fiscal  Tobin's Q    EPS  Liquidity  Profitability  \\\n",
       "0               False      False  False      False          False   \n",
       "1               False      False  False      False          False   \n",
       "2               False      False  False      False          False   \n",
       "3               False      False  False      False          False   \n",
       "4               False      False  False      False          False   \n",
       "\n",
       "   Productivity  Leverage Ratio  Asset Turnover  Operational Margin  \\\n",
       "0         False           False           False               False   \n",
       "1         False           False           False               False   \n",
       "2         False           False           False               False   \n",
       "3         False           False           False               False   \n",
       "4         False           False           False               False   \n",
       "\n",
       "   Return on Equity  Market Book Ratio  Assets Growth  Sales Growth  \\\n",
       "0             False              False           True          True   \n",
       "1             False              False          False         False   \n",
       "2             False              False          False         False   \n",
       "3             False              False          False         False   \n",
       "4             False              False          False         False   \n",
       "\n",
       "   Employee Growth     BK  \n",
       "0             True  False  \n",
       "1            False  False  \n",
       "2            False  False  \n",
       "3            False  False  \n",
       "4            False  False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data Year - Fiscal       0\n",
       "Tobin's Q              252\n",
       "EPS                      5\n",
       "Liquidity              247\n",
       "Profitability          247\n",
       "Productivity           247\n",
       "Leverage Ratio          26\n",
       "Asset Turnover         247\n",
       "Operational Margin    5557\n",
       "Return on Equity         8\n",
       "Market Book Ratio       57\n",
       "Assets Growth         6701\n",
       "Sales Growth          6701\n",
       "Employee Growth       7010\n",
       "BK                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81204, 15)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(how='any').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill missingdata values with mean column values\n",
    "data.fillna(data.mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Year - Fiscal    0\n",
      "Tobin's Q             0\n",
      "EPS                   0\n",
      "Liquidity             0\n",
      "Profitability         0\n",
      "Productivity          0\n",
      "Leverage Ratio        0\n",
      "Asset Turnover        0\n",
      "Operational Margin    0\n",
      "Return on Equity      0\n",
      "Market Book Ratio     0\n",
      "Assets Growth         0\n",
      "Sales Growth          0\n",
      "Employee Growth       0\n",
      "BK                    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# count the number of NaN values in each column\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92872, 15)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training = data[0:90000]\n",
    "testing = data[90000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 15)\n",
      "(2872, 15)\n"
     ]
    }
   ],
   "source": [
    "print(training.shape)\n",
    "print(testing.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(90000, 15)\n",
      "(90000,)\n"
     ]
    }
   ],
   "source": [
    "#Create independent and Dependent Features\n",
    "columns = training.columns.tolist()\n",
    "# Filter the columns to remove data we do not want \n",
    "columns = [c for c in columns if c not in [\"Class\"]]\n",
    "# Store the variable we are predicting \n",
    "target = \"BK\"\n",
    "# Define a random state \n",
    "state = np.random.RandomState(42)\n",
    "X = training[columns]\n",
    "Y = training[target]\n",
    "# Print the shapes of X & Y\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2872, 15)\n",
      "(2872,)\n"
     ]
    }
   ],
   "source": [
    "#Create independent and Dependent Features\n",
    "columns = testing.columns.tolist()\n",
    "# Filter the columns to remove data we do not want \n",
    "columns = [c for c in columns if c not in [\"Class\"]]\n",
    "# Store the variable we are predicting \n",
    "target = \"BK\"\n",
    "# Define a random state \n",
    "state = np.random.RandomState(42)\n",
    "XT = testing[columns]\n",
    "YT = testing[target]\n",
    "# Print the shapes of X & Y\n",
    "print(XT.shape)\n",
    "print(YT.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'BK')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sklearn\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report,accuracy_score\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from pylab import rcParams\n",
    "rcParams['figure.figsize'] = 14, 8\n",
    "RANDOM_SEED = 42\n",
    "LABELS = [\"no_bankruptcy\", \"bankruptcy\"]\n",
    "\n",
    "\n",
    "count_classes = pd.value_counts(training['BK'], sort = True)\n",
    "\n",
    "count_classes.plot(kind = 'bar', rot=0)\n",
    "\n",
    "plt.title(\"Transaction Class Distribution\")\n",
    "\n",
    "plt.xticks(range(2), LABELS)\n",
    "\n",
    "plt.xlabel(\"BK\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from imblearn.under_sampling import NearMiss\n",
    "# Implementing Undersampling for Handling Imbalanced \n",
    "# define the undersampling method\n",
    "undersample = NearMiss(version=1, n_neighbors=3)\n",
    "# transform the dataset\n",
    "X_res,y_res = undersample.fit_resample(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((316, 15), (316,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape,y_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({0: 89842, 1: 158})\n",
      "Resampled dataset shape Counter({0: 158, 1: 158})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "print('Original dataset shape {}'.format(Counter(Y)))\n",
    "print('Resampled dataset shape {}'.format(Counter(y_res)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.asarray(X_res)\n",
    "train_y = np.asarray(y_res)\n",
    "test_x = np.asarray(XT)\n",
    "test_y = np.asarray(YT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_5 (Conv1D)            (None, 13, 128)           512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 769       \n",
      "=================================================================\n",
      "Total params: 1,281\n",
      "Trainable params: 1,281\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 316 samples, validate on 2872 samples\n",
      "Epoch 1/10\n",
      "316/316 [==============================] - 2s 5ms/sample - loss: 13.4829 - accuracy: 0.4842 - val_loss: 17.4949 - val_accuracy: 0.6699\n",
      "Epoch 2/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 8.9794 - accuracy: 0.5380 - val_loss: 28.4363 - val_accuracy: 0.5717\n",
      "Epoch 3/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 7.7999 - accuracy: 0.5665 - val_loss: 41.2890 - val_accuracy: 0.1393\n",
      "Epoch 4/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 7.1921 - accuracy: 0.5759 - val_loss: 49.4414 - val_accuracy: 0.3625\n",
      "Epoch 5/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 4.9654 - accuracy: 0.5949 - val_loss: 54.0861 - val_accuracy: 0.6967\n",
      "Epoch 6/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 4.6786 - accuracy: 0.6203 - val_loss: 69.4442 - val_accuracy: 0.4600\n",
      "Epoch 7/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 2.8620 - accuracy: 0.7278 - val_loss: 77.6823 - val_accuracy: 0.5588\n",
      "Epoch 8/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 2.4955 - accuracy: 0.7500 - val_loss: 84.7855 - val_accuracy: 0.5380\n",
      "Epoch 9/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 2.2817 - accuracy: 0.7184 - val_loss: 92.0919 - val_accuracy: 0.5860\n",
      "Epoch 10/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 2.0406 - accuracy: 0.7184 - val_loss: 101.0316 - val_accuracy: 0.5359\n",
      "Accuracy: 53.59%\n"
     ]
    }
   ],
   "source": [
    "# build network layers\n",
    "model = Sequential()\n",
    "model.add(Conv1D(128,3,input_shape=(15, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=10, batch_size=10)\n",
    "\n",
    "# score model and log accuracy and parameters\n",
    "scores = model.evaluate(test_x, test_y, verbose=0)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN\n",
    "\n",
    "#reshape input to be [samples, time steps, features] which is required for CNN\n",
    "train_x =train_x.reshape(train_x.shape[0],train_x.shape[1] , 1)\n",
    "test_x = test_x.reshape(test_x.shape[0],test_x.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, MaxPool1D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(32, 3, activation='relu', input_shape = (256,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(64, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(128, 3, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# build LSTM layers\n",
    "model = Sequential()\n",
    "model.add(LSTM(100, dropout=0.2, input_shape=(15,1)))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 100)               40800     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 40,901\n",
      "Trainable params: 40,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00005), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 316 samples, validate on 2872 samples\n",
      "Epoch 1/10\n",
      "316/316 [==============================] - 7s 22ms/sample - loss: 0.6363 - accuracy: 0.7215 - val_loss: 0.6648 - val_accuracy: 0.7430\n",
      "Epoch 2/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.5034 - accuracy: 0.8038 - val_loss: 1.0279 - val_accuracy: 0.4620\n",
      "Epoch 3/10\n",
      "316/316 [==============================] - 1s 2ms/sample - loss: 0.3415 - accuracy: 0.8829 - val_loss: 1.4456 - val_accuracy: 0.4394\n",
      "Epoch 4/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.3097 - accuracy: 0.8766 - val_loss: 2.0734 - val_accuracy: 0.3548\n",
      "Epoch 5/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.2805 - accuracy: 0.8987 - val_loss: 2.1533 - val_accuracy: 0.3482\n",
      "Epoch 6/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.2697 - accuracy: 0.8987 - val_loss: 2.3006 - val_accuracy: 0.3409\n",
      "Epoch 7/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.2346 - accuracy: 0.8956 - val_loss: 2.4401 - val_accuracy: 0.3336\n",
      "Epoch 8/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.1941 - accuracy: 0.9241 - val_loss: 2.5494 - val_accuracy: 0.3377\n",
      "Epoch 9/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.2286 - accuracy: 0.9177 - val_loss: 2.7824 - val_accuracy: 0.3102\n",
      "Epoch 10/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.2109 - accuracy: 0.9114 - val_loss: 2.9633 - val_accuracy: 0.2782\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1b78f847ec8>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x , train_y, epochs=10, validation_data=(test_x, test_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and continuous targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-84-38be1d36bc36>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36maccuracy_score\u001b[1;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[0;32m    185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Compute accuracy for each possible representation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 187\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    188\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'multilabel'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\metrics\\_classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 91\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and continuous targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(8, 2, activation='relu', input_shape = (15,1)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Conv1D(10, 2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Conv1D(12, 2, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPool1D(2))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(15, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Total params: 0\n",
      "Trainable params: 0\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(128,3,input_shape=(15, 1)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPool1D(pool_size=2))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00005), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 316 samples, validate on 2872 samples\n",
      "Epoch 1/10\n",
      "316/316 [==============================] - 5s 15ms/sample - loss: 39.0208 - accuracy: 0.5000 - val_loss: 4.1518 - val_accuracy: 0.8611\n",
      "Epoch 2/10\n",
      "316/316 [==============================] - 0s 1ms/sample - loss: 26.4953 - accuracy: 0.5000 - val_loss: 3.3313 - val_accuracy: 0.8593\n",
      "Epoch 3/10\n",
      "316/316 [==============================] - 0s 733us/sample - loss: 17.9988 - accuracy: 0.4620 - val_loss: 2.7292 - val_accuracy: 0.8562\n",
      "Epoch 4/10\n",
      "316/316 [==============================] - 0s 681us/sample - loss: 36.8824 - accuracy: 0.4557 - val_loss: 2.2951 - val_accuracy: 0.8482\n",
      "Epoch 5/10\n",
      "316/316 [==============================] - 0s 669us/sample - loss: 25.9684 - accuracy: 0.4747 - val_loss: 2.0395 - val_accuracy: 0.8381\n",
      "Epoch 6/10\n",
      "316/316 [==============================] - 0s 600us/sample - loss: 23.1565 - accuracy: 0.4652 - val_loss: 1.9875 - val_accuracy: 0.8123\n",
      "Epoch 7/10\n",
      "316/316 [==============================] - 0s 684us/sample - loss: 32.0672 - accuracy: 0.5316 - val_loss: 2.2665 - val_accuracy: 0.7664\n",
      "Epoch 8/10\n",
      "316/316 [==============================] - 0s 672us/sample - loss: 29.6845 - accuracy: 0.5348 - val_loss: 2.8539 - val_accuracy: 0.6793\n",
      "Epoch 9/10\n",
      "316/316 [==============================] - 0s 658us/sample - loss: 27.0259 - accuracy: 0.5032 - val_loss: 3.3876 - val_accuracy: 0.5547\n",
      "Epoch 10/10\n",
      "316/316 [==============================] - 0s 659us/sample - loss: 17.6506 - accuracy: 0.4620 - val_loss: 3.7901 - val_accuracy: 0.4554\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ed9ffcca88>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x , train_y, epochs=10, validation_data=(test_x, test_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 316 samples, validate on 2872 samples\n",
      "Epoch 1/10\n",
      "316/316 [==============================] - 10s 30ms/sample - loss: 1.1674 - accuracy: 0.5127 - val_loss: 5.9490 - val_accuracy: 0.1393\n",
      "Epoch 2/10\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 1.2208 - accuracy: 0.4873 - val_loss: 3.9107 - val_accuracy: 0.1393\n",
      "Epoch 3/10\n",
      "316/316 [==============================] - 0s 953us/sample - loss: 1.1477 - accuracy: 0.4905 - val_loss: 3.0608 - val_accuracy: 0.1393\n",
      "Epoch 4/10\n",
      "316/316 [==============================] - 0s 841us/sample - loss: 1.1676 - accuracy: 0.4968 - val_loss: 2.5577 - val_accuracy: 0.1393\n",
      "Epoch 5/10\n",
      "316/316 [==============================] - 0s 831us/sample - loss: 1.0988 - accuracy: 0.5222 - val_loss: 2.2202 - val_accuracy: 0.1393\n",
      "Epoch 6/10\n",
      "316/316 [==============================] - 0s 857us/sample - loss: 1.1448 - accuracy: 0.5127 - val_loss: 1.9804 - val_accuracy: 0.1393\n",
      "Epoch 7/10\n",
      "316/316 [==============================] - 0s 791us/sample - loss: 1.0678 - accuracy: 0.4968 - val_loss: 1.7964 - val_accuracy: 0.1393\n",
      "Epoch 8/10\n",
      "316/316 [==============================] - 0s 864us/sample - loss: 1.1544 - accuracy: 0.5063 - val_loss: 1.6672 - val_accuracy: 0.1393\n",
      "Epoch 9/10\n",
      "316/316 [==============================] - 0s 836us/sample - loss: 1.0587 - accuracy: 0.5127 - val_loss: 1.5423 - val_accuracy: 0.1393\n",
      "Epoch 10/10\n",
      "316/316 [==============================] - 0s 803us/sample - loss: 1.1615 - accuracy: 0.4715 - val_loss: 1.4534 - val_accuracy: 0.1393\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(train_x, train_y, epochs=10, validation_data=(test_x, test_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=0.00005), loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "A target array with shape (316, 1) was passed for an output of shape (None, 15) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-e905fbcec720>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2536\u001b[0m           \u001b[1;31m# Additional checks to avoid users mistakenly using improper loss fns.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2537\u001b[0m           training_utils.check_loss_and_target_compatibility(\n\u001b[1;32m-> 2538\u001b[1;33m               y, self._feed_loss_fns, feed_output_shapes)\n\u001b[0m\u001b[0;32m   2539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2540\u001b[0m       \u001b[1;31m# If sample weight mode has not been set and weights are None for all the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mcheck_loss_and_target_compatibility\u001b[1;34m(targets, loss_fns, output_shapes)\u001b[0m\n\u001b[0;32m    741\u001b[0m           raise ValueError('A target array with shape ' + str(y.shape) +\n\u001b[0;32m    742\u001b[0m                            \u001b[1;34m' was passed for an output of shape '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 743\u001b[1;33m                            \u001b[1;34m' while using as loss `'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mloss_name\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'`. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    744\u001b[0m                            \u001b[1;34m'This loss expects targets to have the same shape '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    745\u001b[0m                            'as the output.')\n",
      "\u001b[1;31mValueError\u001b[0m: A target array with shape (316, 1) was passed for an output of shape (None, 15) while using as loss `binary_crossentropy`. This loss expects targets to have the same shape as the output."
     ]
    }
   ],
   "source": [
    "history = model.fit(train_x , train_y, epochs=10, validation_data=(test_x, test_y), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.754172362858736,\n",
       "  0.8130169375033318,\n",
       "  0.8347221182871468,\n",
       "  0.7640596786631814,\n",
       "  0.790756153909466,\n",
       "  0.8701013432273382,\n",
       "  0.8040449264683301,\n",
       "  0.8068985342979431,\n",
       "  0.7666553915301456,\n",
       "  0.7634494636632219],\n",
       " 'accuracy': [0.54746836,\n",
       "  0.5,\n",
       "  0.43670887,\n",
       "  0.5316456,\n",
       "  0.5221519,\n",
       "  0.5063291,\n",
       "  0.46518987,\n",
       "  0.47468355,\n",
       "  0.49683544,\n",
       "  0.5],\n",
       " 'val_loss': [1.1877896490203306,\n",
       "  1.019304598938456,\n",
       "  0.9489431811242383,\n",
       "  0.9037680302157708,\n",
       "  0.8735595189429259,\n",
       "  0.8530979181398588,\n",
       "  0.8400020028223234,\n",
       "  0.829654664880386,\n",
       "  0.8198662893353731,\n",
       "  0.8144528879096581],\n",
       " 'val_accuracy': [0.13927576,\n",
       "  0.13927576,\n",
       "  0.13927576,\n",
       "  0.15389971,\n",
       "  0.17270195,\n",
       "  0.17374651,\n",
       "  0.17374651,\n",
       "  0.17688023,\n",
       "  0.17688023,\n",
       "  0.17653203]}"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d51b16e99c4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m   \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[0mplot_learningCurve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "def plot_learningCurve(history, epoch):\n",
    "  # Plot training & validation accuracy values\n",
    "  epoch_range = range(1, epoch+1)\n",
    "  plt.plot(epoch_range, history.history['accuracy'])\n",
    "  plt.plot(epoch_range, history.history['val_accuracy'])\n",
    "  plt.title('Model accuracy')\n",
    "  plt.ylabel('Accuracy')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "  # Plot training & validation loss values\n",
    "  plt.plot(epoch_range, history.history['loss'])\n",
    "  plt.plot(epoch_range, history.history['val_loss'])\n",
    "  plt.title('Model loss')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.legend(['Train', 'Val'], loc='upper left')\n",
    "  plt.show()\n",
    "\n",
    "plot_learningCurve(history, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "train_x =train_x.reshape(train_x.shape[0],train_x.shape[1] , 1)\n",
    "test_x = test_x.reshape(test_x.shape[0],test_x.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(15,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3 (LSTM)                (None, 15, 50)            10400     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 15, 50)            20200     \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 50,851\n",
      "Trainable params: 50,851\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 316 samples, validate on 2872 samples\n",
      "Epoch 1/100\n",
      "316/316 [==============================] - 17s 55ms/sample - loss: 0.3238 - val_loss: 0.3332\n",
      "Epoch 2/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.1735 - val_loss: 0.4707\n",
      "Epoch 3/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.1407 - val_loss: 0.3207\n",
      "Epoch 4/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.1348 - val_loss: 0.3979\n",
      "Epoch 5/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.1155 - val_loss: 0.4552\n",
      "Epoch 6/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.1031 - val_loss: 0.4404\n",
      "Epoch 7/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0934 - val_loss: 0.5540\n",
      "Epoch 8/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0838 - val_loss: 0.5938\n",
      "Epoch 9/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0762 - val_loss: 0.6803\n",
      "Epoch 10/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0733 - val_loss: 0.5814\n",
      "Epoch 11/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0640 - val_loss: 0.6784\n",
      "Epoch 12/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0584 - val_loss: 0.5947\n",
      "Epoch 13/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0565 - val_loss: 0.6269\n",
      "Epoch 14/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0516 - val_loss: 0.6297\n",
      "Epoch 15/100\n",
      "316/316 [==============================] - 1s 4ms/sample - loss: 0.0492 - val_loss: 0.6817\n",
      "Epoch 16/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0490 - val_loss: 0.6231\n",
      "Epoch 17/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0494 - val_loss: 0.6297\n",
      "Epoch 18/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0496 - val_loss: 0.7169\n",
      "Epoch 19/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0507 - val_loss: 0.6126\n",
      "Epoch 20/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0536 - val_loss: 0.5805\n",
      "Epoch 21/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0525 - val_loss: 0.6949\n",
      "Epoch 22/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0502 - val_loss: 0.5956\n",
      "Epoch 23/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0477 - val_loss: 0.6968\n",
      "Epoch 24/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0485 - val_loss: 0.6642\n",
      "Epoch 25/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0506 - val_loss: 0.6378\n",
      "Epoch 26/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0457 - val_loss: 0.6490\n",
      "Epoch 27/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0429 - val_loss: 0.6751\n",
      "Epoch 28/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0450 - val_loss: 0.6368\n",
      "Epoch 29/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0444 - val_loss: 0.7209\n",
      "Epoch 30/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0451 - val_loss: 0.6629\n",
      "Epoch 31/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0424 - val_loss: 0.6835\n",
      "Epoch 32/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0418 - val_loss: 0.6772\n",
      "Epoch 33/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0431 - val_loss: 0.6429\n",
      "Epoch 34/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0416 - val_loss: 0.7076\n",
      "Epoch 35/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0421 - val_loss: 0.6583\n",
      "Epoch 36/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0447 - val_loss: 0.6961\n",
      "Epoch 37/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0418 - val_loss: 0.6709\n",
      "Epoch 38/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0410 - val_loss: 0.6738\n",
      "Epoch 39/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0407 - val_loss: 0.6924\n",
      "Epoch 40/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0429 - val_loss: 0.7071\n",
      "Epoch 41/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0419 - val_loss: 0.6778\n",
      "Epoch 42/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0407 - val_loss: 0.6871\n",
      "Epoch 43/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0401 - val_loss: 0.6828\n",
      "Epoch 44/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0404 - val_loss: 0.6779\n",
      "Epoch 45/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0411 - val_loss: 0.7028\n",
      "Epoch 46/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0412 - val_loss: 0.6443\n",
      "Epoch 47/100\n",
      "316/316 [==============================] - 1s 4ms/sample - loss: 0.0456 - val_loss: 0.7141\n",
      "Epoch 48/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0452 - val_loss: 0.6371\n",
      "Epoch 49/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0456 - val_loss: 0.7102\n",
      "Epoch 50/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0432 - val_loss: 0.6645\n",
      "Epoch 51/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0419 - val_loss: 0.6782\n",
      "Epoch 52/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0400 - val_loss: 0.6743\n",
      "Epoch 53/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0404 - val_loss: 0.7035\n",
      "Epoch 54/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0406 - val_loss: 0.6619\n",
      "Epoch 55/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0412 - val_loss: 0.7115\n",
      "Epoch 56/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0401 - val_loss: 0.6735\n",
      "Epoch 57/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0405 - val_loss: 0.7060\n",
      "Epoch 58/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0414 - val_loss: 0.6651\n",
      "Epoch 59/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0403 - val_loss: 0.7003\n",
      "Epoch 60/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0390 - val_loss: 0.6653\n",
      "Epoch 61/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0391 - val_loss: 0.7036\n",
      "Epoch 62/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0398 - val_loss: 0.6732\n",
      "Epoch 63/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0392 - val_loss: 0.6948\n",
      "Epoch 64/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0395 - val_loss: 0.6919\n",
      "Epoch 65/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0393 - val_loss: 0.6777\n",
      "Epoch 66/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0388 - val_loss: 0.6996\n",
      "Epoch 67/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0393 - val_loss: 0.6785\n",
      "Epoch 68/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0386 - val_loss: 0.6948\n",
      "Epoch 69/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0386 - val_loss: 0.7000\n",
      "Epoch 70/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0384 - val_loss: 0.6896\n",
      "Epoch 71/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0387 - val_loss: 0.6775\n",
      "Epoch 72/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0385 - val_loss: 0.7123\n",
      "Epoch 73/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0383 - val_loss: 0.6757\n",
      "Epoch 74/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0406 - val_loss: 0.7030\n",
      "Epoch 75/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0403 - val_loss: 0.6816\n",
      "Epoch 76/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0391 - val_loss: 0.6818\n",
      "Epoch 77/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0401 - val_loss: 0.6900\n",
      "Epoch 78/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0400 - val_loss: 0.6805\n",
      "Epoch 79/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0401 - val_loss: 0.7115\n",
      "Epoch 80/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0401 - val_loss: 0.6699\n",
      "Epoch 81/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0382 - val_loss: 0.7264\n",
      "Epoch 82/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0387 - val_loss: 0.6637\n",
      "Epoch 83/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0391 - val_loss: 0.7041\n",
      "Epoch 84/100\n",
      "316/316 [==============================] - 1s 4ms/sample - loss: 0.0374 - val_loss: 0.6714\n",
      "Epoch 85/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0368 - val_loss: 0.7151\n",
      "Epoch 86/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0386 - val_loss: 0.6774\n",
      "Epoch 87/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0375 - val_loss: 0.7094\n",
      "Epoch 88/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0376 - val_loss: 0.6824\n",
      "Epoch 89/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0367 - val_loss: 0.6978\n",
      "Epoch 90/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0370 - val_loss: 0.6880\n",
      "Epoch 91/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0370 - val_loss: 0.6995\n",
      "Epoch 92/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0381 - val_loss: 0.6782\n",
      "Epoch 93/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0394 - val_loss: 0.7170\n",
      "Epoch 94/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0376 - val_loss: 0.6411\n",
      "Epoch 95/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0411 - val_loss: 0.7088\n",
      "Epoch 96/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0379 - val_loss: 0.6683\n",
      "Epoch 97/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0376 - val_loss: 0.7134\n",
      "Epoch 98/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0384 - val_loss: 0.6749\n",
      "Epoch 99/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0381 - val_loss: 0.6836\n",
      "Epoch 100/100\n",
      "316/316 [==============================] - 1s 3ms/sample - loss: 0.0363 - val_loss: 0.7003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x27fc3c56608>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_x,train_y,validation_data=(test_x,test_y),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model.predict(train_x)\n",
    "test_predict=model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18833792974268387"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Calculate RMSE performance metrics\n",
    "import math\n",
    "from sklearn.metrics import mean_squared_error\n",
    "math.sqrt(mean_squared_error(train_y,train_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8368202959998177"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "### Test Data RMSE\n",
    "math.sqrt(mean_squared_error(test_y,test_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-d6b7090d83bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneural_network\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmlp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMLPClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhidden_layer_sizes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m13\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m   1026\u001b[0m         \"\"\"\n\u001b[0;32m   1027\u001b[0m         return self._fit(X, y, incremental=(self.warm_start and\n\u001b[1;32m-> 1028\u001b[1;33m                                             hasattr(self, \"classes_\")))\n\u001b[0m\u001b[0;32m   1029\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1030\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_fit\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    324\u001b[0m                              hidden_layer_sizes)\n\u001b[0;32m    325\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m         \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36m_validate_input\u001b[1;34m(self, X, y, incremental)\u001b[0m\n\u001b[0;32m    963\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_validate_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincremental\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    964\u001b[0m         X, y = self._validate_data(X, y, accept_sparse=['csr', 'csc'],\n\u001b[1;32m--> 965\u001b[1;33m                                    multi_output=True)\n\u001b[0m\u001b[0;32m    966\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    967\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    800\u001b[0m                     \u001b[0mensure_min_samples\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    801\u001b[0m                     \u001b[0mensure_min_features\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_min_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 802\u001b[1;33m                     estimator=estimator)\n\u001b[0m\u001b[0;32m    803\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    804\u001b[0m         y = check_array(y, accept_sparse='csr', force_all_finite=True,\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    639\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 641\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    642\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 3. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(13,10,2),max_iter=1000)\n",
    "mlp.fit(train_x,train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This MLPClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-85cc285f6ca8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmlp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1001\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1002\u001b[0m         \"\"\"\n\u001b[1;32m-> 1003\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1004\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1005\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1017\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1018\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1019\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1020\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1021\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This MLPClassifier instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "predictions =mlp.predict(test_x)\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "cm=confusion_matrix(test_y,predictions)\n",
    "print(confusion_matrix(test_y,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, center=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7353760445682451"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test_y,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    " clf = MLPClassifier(random_state=1, max_iter=300).fit(train_x,train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.52750165, 0.47249835]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict_proba(test_x[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict(test_x[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4491643454038997"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(100,100,100), max_iter=500, alpha=0.0001,\n",
    "                     solver='sgd', verbose=10,  random_state=21,tol=0.000000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 17.90784930\n",
      "Iteration 2, loss = 17.33756298\n",
      "Iteration 3, loss = 17.79429245\n",
      "Iteration 4, loss = 19.16533418\n",
      "Iteration 5, loss = 17.57260763\n",
      "Iteration 6, loss = 21.26488941\n",
      "Iteration 7, loss = 24.15379785\n",
      "Iteration 8, loss = 9583.84506547\n",
      "Iteration 9, loss = 25027.31967172\n",
      "Iteration 10, loss = 43048.16262786\n",
      "Iteration 11, loss = 61262.24213211\n",
      "Iteration 12, loss = 78388.89005613\n",
      "Iteration 13, loss = 93818.55939868\n",
      "Training loss did not improve more than tol=0.000000 for 10 consecutive epochs. Stopping.\n"
     ]
    }
   ],
   "source": [
    "clf.fit(train_x,train_y)\n",
    "y_pred = clf.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1392757660167131"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0, 2472],\n",
       "       [   0,  400]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm = confusion_matrix(test_y, y_pred)\n",
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(cm, center=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
